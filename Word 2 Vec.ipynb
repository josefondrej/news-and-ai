{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words to numbers\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.word_2_vec import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of words from text sorted by their count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = load_data(\"./resources/grimm_fairy_tales.txt\")\n",
    "unique_words = list(set(text_corpus))\n",
    "unique_word_counts = [(word, count_word(word, text_corpus)) for word in unique_words]\n",
    "sort_word_counts(unique_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 3674),\n",
      " ('and', 2613),\n",
      " ('to', 1328),\n",
      " ('a', 931),\n",
      " ('he', 915),\n",
      " ('of', 836),\n",
      " ('she', 768),\n",
      " ('her', 693),\n",
      " ('was', 675),\n",
      " ('in', 668)]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(unique_word_counts[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count coocurences of each unique word with preselected list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words = ['replied', 'himself', 'can', 'daughter', 'queen', 'beautiful', 'should', 'over', 'told', \n",
    "                  'work', 'take', 'cried', 'mother', 'long', 'more', 'last', 'asked', 'however', 'once', \n",
    "                  'woman', 'too', 'us', 'good', 'heard', 'been', 'tree', 'nothing', 'called', 'than', 'put', \n",
    "                  'back', 'water', 'am', 'tailor', 'morning', 'saying', 'kings', 'wife', 'only', 'children', \n",
    "                  'way', 'still', 'ran', 'may', 'made', 'gutenbergtm', 'make', 'well', 'began', 'give', 'set', \n",
    "                  'while', 'forest', 'has', 'dear', 'gold', 'quite', 'through', 'golden', 'looked', 'sat', \n",
    "                  'sister', 'prince', 'till', 'gave', 'snowwhite', 'oh', 'fire', 'here', 'answered', 'much', \n",
    "                  'got', 'found', 'ah', 'first', 'three', 'bed', 'like', 'fell', 'might', 'done', 'get', \n",
    "                  'herself', 'house', 'every', 'night', 'bride', 'hansel', 'young', 'heart', 'eat', 'son', \n",
    "                  'john', 'eyes', 'stood', 'each', 'know', 'dwarf', 'bread', 'full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_file_path = \"./resources/serialized_word_vectors.pickle\"\n",
    "\n",
    "if os.path.exists(word_vectors_file_path):\n",
    "    word_vectors = pickle.load(open(word_vectors_file_path, \"rb\"))\n",
    "else:\n",
    "    word_vectors = dict()\n",
    "    for word in tqdm(unique_words):\n",
    "        word_vectors[word] = [count_coocurences(word, selected_word, text_corpus, 5) \n",
    "                              for selected_word in selected_words]\n",
    "    pickle.dump(word_vectors, open(word_vectors_file_path, \"wb\"))\n",
    "    \n",
    "word_vectors = {w: np.array(v) for w, v in word_vectors.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors[\"silver\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(wordA, wordB, w2v):\n",
    "    vecA = w2v[wordA]\n",
    "    vecB = w2v[wordB]\n",
    "    return np.sum(vecA * vecB) / np.sqrt(np.sum(vecA**2) * np.sum(vecB**2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9015749926333749"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(\"gold\", \"silver\", word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josef/anaconda3/envs/tf2/lib/python3.7/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['silver',\n",
       " 'gold',\n",
       " 'lighted',\n",
       " 'thingsjewels',\n",
       " 'fruits',\n",
       " 'treasures',\n",
       " 'sticking',\n",
       " 'glistening',\n",
       " 'woven',\n",
       " 'garmented']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_sorted_by_similarity(\"silver\", word_vectors)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing words by their temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_words = [\"hot\", \"fire\"]\n",
    "cold_words = [\"cold\", \"ice\"]\n",
    "\n",
    "def word_temperature(word): \n",
    "    hotness = np.max([similarity(word, hot_word, word_vectors) for hot_word in hot_words])\n",
    "    coldness = np.max([similarity(word, cold_word, word_vectors) for cold_word in cold_words])\n",
    "    return hotness - coldness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.14805308450943983"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_temperature(\"snow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.16666666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_temperature(\"frozen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06319202925257428"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_temperature(\"shiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04438185846777611"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_temperature(\"sun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12931200729757436"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_temperature(\"bright\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024182541670333724"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_temperature(\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_temperature(\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047794944556367035"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_temperature(\"yellow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://www.twinword.com/api/sentiment-analysis.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
